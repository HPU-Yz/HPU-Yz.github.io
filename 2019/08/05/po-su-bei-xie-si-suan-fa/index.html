<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Best-yz"><title>朴素贝叶斯算法 · Best-yz</title><meta name="description" content="&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;朴素贝叶斯算法是流行的十大算法之一，该算法是有监督的学习算法，解决的是分类问题，如客户是否流失、是否值得投资、信用等级评定等多分类问题。该算法的优点在于简单易懂、学习效率高、在某些领域的分类问题中能够与决"><meta name="keywords" content="Flaneur博客，Best-yz博客"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">Best-yz</a></h3><div class="description"><p>三分热度 <br> Nothing is impossible to a willing heart.</p></div></div></div><ul class="social-links"><li><a href="https://github.com/HPU-Yz"><i class="fa fa-github"></i></a></li><li><a href="mailto:2426545812@qq.com"><i class="fa fa-envelope"></i></a></li><li><a href="http://sighttp.qq.com/authd?IDKEY=da97a3288889b7c35a1e6d914e0cb28bda9a83ec1e77cf7b"><i class="fa fa-qq"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2019 - 2020 </span><i class="fa fa-star"></i><span> Best-yz</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> </span><a href="http://www.beian.miit.gov.cn/" target="_blank">&nbsp;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><li><a href="/guestbook">留言</a></li><li><a href="/links">友链</a></li><li><a href="/shuoshuo">说说</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>朴素贝叶斯算法</a></h3></div><div class="post-content"><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;朴素贝叶斯算法是流行的十大算法之一，该算法是有监督的学习算法，解决的是分类问题，如客户是否流失、是否值得投资、信用等级评定等多分类问题。<strong>该算法的优点在于简单易懂、学习效率高、在某些领域的分类问题中能够与决策树、神经网络相媲美。</strong>但由于该算法以自变量之间的独立（条件特征独立）性和连续变量的正态性假设为前提，就会导致算法精度在某种程度上受影响。</p>
<h1 id="一、问题的提出"><a href="#一、问题的提出" class="headerlink" title="一、问题的提出"></a>一、问题的提出</h1><p>先举一个具体的例子：</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;“一所学校里面有 60% 的男生，40% 的女生。男生总是穿长裤，女生则一半穿长裤一半穿裙子。有了这些信息之后我们可以容易地计算“随机选取一个学生，他（她）穿长裤的概率和穿裙子的概率是多大”，这个就是前面说的“正向概率”的计算。然而，假设你走在校园中，迎面走来一个穿长裤的学生（很不幸的是你高度近似，你只看得见他（她）穿的是否长裤，而无法确定他（她）的性别），你能够推断出他（她）是男生的概率是多大吗？”</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们来算一算：假设学校里面人的总数是 U 个。60% 的男生都穿长裤，于是我们得到了 U <em> P(Boy) </em> P(Pants|Boy) 个穿长裤的（男生）（其中 P(Boy) 是男生的概率 = 60%，这里可以简单的理解为男生的比例；P(Pants|Boy) 是条件概率，即在 Boy 这个条件下穿长裤的概率是多大，这里是 100% ，因为所有男生都穿长裤）。40% 的女生里面又有一半（50%）是穿长裤的，于是我们又得到了 U <em> P(Girl) </em> P(Pants|Girl) 个穿长裤的（女生）。加起来一共是 U <em> P(Boy) </em> P(Pants|Boy) + U <em> P(Girl) </em> P(Pants|Girl) 个穿长裤的，其中有 U <em> P(Girl) </em> P(Pants|Girl) 个女生。两者一比就是你要求的答案。<br>下面我们把这个答案形式化一下：我们要求的是 P(Girl|Pants) （穿长裤的人里面有多少女生），我们计算的结果是 U <em> P(Girl) </em> P(Pants|Girl) / [U <em> P(Boy) </em> P(Pants|Boy) + U <em> P(Girl) </em> P(Pants|Girl)] 。容易发现这里校园内人的总数是无关的，可以消去。于是得到</p>
<p><strong>P(Girl|Pants) = P(Girl) <em> P(Pants|Girl) / [P(Boy) </em> P(Pants|Boy) + P(Girl) * P(Pants|Girl)]</strong></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;注意，如果把上式收缩起来，分母其实就是 P(Pants) ，分子其实就是 P(Pants, Girl) 。而这个比例很自然地就读作：在穿长裤的人（ P(Pants) ）里面有多少（穿长裤）的女孩（ P(Pants, Girl) ）。<br>进一步得到公式的一般形式：</p>
<p><strong>P(B|A) = P(A|B) <em> P(B) / [P(A|B) </em> P(B) + P(A|~B) * P(~B) ]</strong></p>
<p>收缩起来就是：<strong>P(B|A) = P(AB) / P(A)</strong><br>其实这个就等于：<strong>P(B|A) * P(A) = P(AB)</strong></p>
<h1 id="二、正式的定义"><a href="#二、正式的定义" class="headerlink" title="二、正式的定义"></a>二、正式的定义</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;朴素贝叶斯算法是基于贝叶斯定理与特征条件独立假设的分类方法，然后依据被分类项属于各个类的概率，概率最大者即为所划分的类别。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;设输入空间X=（x1,x2,x3…xn），输出类标记为Y=（y1,y2,y3…yn）。x的集合记为X，称为属性集。一般X和Y的关系不确定的，你只能在某种程度上说x有多大可能性属于类y1，比如说x有80%的可能性属于类y1，这时可以把X和Y看做是随机变量，P(Y|X)称为Y的<strong>后验概率</strong>（posterior probability），与之相对的P(Y)称为Y的<strong>先验概率</strong>（prior probability），P(X=x|Y=y1)称之为<strong>条件概率</strong>。</p>
<p><strong>先验概率</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过经验来判断事情发生的概率，比如说“贝叶死”的发病率是万分之一，就是先验概率。再比如南方的梅雨季是 6-7 月，就是通过往年的气候总结出来的经验，这个时候下雨的概率就比其他时间高出很多。</p>
<p><strong>后验概率</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;后验概率就是发生结果之后，推测原因的概率。比如说某人查出来了患有“贝叶死”，那么患病的原因可能是 A、B 或 C。患有“贝叶死”是因为原因 A 的概率就是后验概率。它是属于条件概率的一种。</p>
<p><strong>条件概率</strong><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事件 A 在另外一个事件 B 已经发生条件下的发生概率，表示为 P(A|B)，读作“在 B 发生的条件下 A 发生的概率”。比如原因 A 的条件下，患有“贝叶死”的概率，就是条件概率。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简单说来就是：贝叶斯分类算法的理论基于贝叶斯公式：<br><img src="https://img-blog.csdnimg.cn/20190816085605498.png" alt></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中P(A|B)称为<strong>条件概率</strong>，P(B)<strong>先验概率</strong>，对应P(B|A)为<strong>后验概率</strong>。朴素贝叶斯分类器基于一个简单的假定，即给定的目标值属性之间是相互独立。贝叶斯公式之所以有用是因为在日常生活中，我们可以很容易得到P(A|B)，而很难得出P(B|A)，但我们更关心P(B|A)，所以就可以根据贝叶斯公式来计算。</p>
<h1 id="三、应用举例"><a href="#三、应用举例" class="headerlink" title="三、应用举例"></a>三、应用举例</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如下表所示，训练数据学习一个朴素贝叶斯分类器并确定x=(2,S)T的类标记y。表中x1、x2为特征，取值的集合分别为X1={1,2,3}，X2={S,M,L}，类标记Y={1,-1}</p>
<p><img src="https://img-blog.csdnimg.cn/20190816084258206.png" alt><br>根据贝叶斯算法得到如下概率：</p>
<p>P(Y=1)=9/15，P(Y=-1)=6/15</p>
<p>P(X1=1|Y=1)=2/9，P(X1=2|Y=1)=3/9，P(X1=3|Y=1)=4/9</p>
<p>P(X2=S|Y=1)=1/9，P(X2=M|Y=1)=4/9，P(X2=L|Y=1)=4/9</p>
<p>P(X1=1|Y=-1)=3/6，P(X1=2|Y=-1)=2/6，P(X1=3|Y=-1)=1/6</p>
<p>P(X2=S|Y=-1)=3/6，P(X2=M|Y=-1)=2/6，P((X2=L|Y=-1)=1/6</p>
<p>所以对于给定的x=(2,S)T计算：</p>
<p>P(Y=1)P(X1=2|Y=1)P(X2=S|Y=1)=(9/15)(3/9)(1/9)=1/45</p>
<p>P(Y=-1)P(X1=2|Y=-1)P(X2=S|Y=-1)=(6/15)(2/6)(1/6)=1/15</p>
<p>所以分类结果为y=-1</p>
<h1 id="四、朴素贝叶斯算法的优缺点"><a href="#四、朴素贝叶斯算法的优缺点" class="headerlink" title="四、朴素贝叶斯算法的优缺点"></a>四、朴素贝叶斯算法的优缺点</h1><p><strong>优点：</strong></p>
<ol>
<li>朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率；</li>
<li>对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已；</li>
<li>对小规模的数据表现很好，能个处理多分类任务，适合增量式训练（即可以实时的对新增的样本进行训练）；</li>
<li>对缺失数据不太敏感，算法也比较简单，常用于文本分类；</li>
<li>朴素贝叶斯对结果解释容易理解。</li>
</ol>
<p> <strong>缺点</strong></p>
<ol>
<li>需要计算先验概率；</li>
<li>分类决策存在错误率；</li>
<li>对输入数据的表达形式很敏感；</li>
<li>由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。</li>
</ol>
<h1 id="五、应用领域"><a href="#五、应用领域" class="headerlink" title="五、应用领域"></a>五、应用领域</h1><ol>
<li>欺诈检测中使用较多；</li>
<li>一封电子邮件是否是垃圾邮件；</li>
<li>一篇文章应该分到科技、政治，还是体育类；</li>
<li>一段文字表达的是积极的情绪还是消极的情绪；</li>
<li>人脸识别</li>
</ol>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2019-08-05</span><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/朴素贝叶斯算法/" title="朴素贝叶斯算法">朴素贝叶斯算法 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://hpu-yz.github.io/2019/08/05/po-su-bei-xie-si-suan-fa/,Best-yz,朴素贝叶斯算法,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2020/03/05/python-dong-tai-gui-hua-jie-jue-ju-zhen-lian-cheng/" title="动态规划解决矩阵连乘">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2019/08/01/qian-tan-ji-qi-xue-xi-hui-gui-yu-fen-lei-de-qu-bie/" title="浅谈机器学习-回归与分类的区别">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'ScFNhrKDxbwGDnwPjE6xGCTm-gzGzoHsz',
  app_key:'Lwnq5xfD0M2LosaGSeDSFeqi',
  placeholder:'念念不忘，必有回响...',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'monsterid'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>