<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Best-yz"><title>推荐系统之矩阵分解(MF)及其python实现 · Best-yz</title><meta name="description" content="&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;目前推荐系统中用的最多的就是矩阵分解方法，在Netflix Prize推荐系统大赛中取得突出效果。以用户-项目评分矩阵为例，矩阵分解就是预测出评分矩阵中的缺失值，然后根据预测值以某种方式向用户推荐。今天以"><meta name="keywords" content="Flaneur博客，Best-yz博客"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title><a href="/">Best-yz</a></h3><div class="description"><p>三分热度 <br> Nothing is impossible to a willing heart.</p></div></div></div><ul class="social-links"><li><a href="https://github.com/HPU-Yz"><i class="fa fa-github"></i></a></li><li><a href="mailto:2426545812@qq.com"><i class="fa fa-envelope"></i></a></li><li><a href="http://sighttp.qq.com/authd?IDKEY=da97a3288889b7c35a1e6d914e0cb28bda9a83ec1e77cf7b"><i class="fa fa-qq"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2019 - 2020 </span><i class="fa fa-star"></i><span> Best-yz</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> </span><a href="http://www.beian.miit.gov.cn/" target="_blank">&nbsp;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><li><a href="/guestbook">留言</a></li><li><a href="/links">友链</a></li><li><a href="/shuoshuo">说说</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>推荐系统之矩阵分解(MF)及其python实现</a></h3></div><div class="post-content"><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前推荐系统中用的最多的就是矩阵分解方法，在Netflix Prize推荐系统大赛中取得突出效果。以用户-项目评分矩阵为例，矩阵分解就是预测出评分矩阵中的缺失值，然后根据预测值以某种方式向用户推荐。今天以“用户-项目评分矩阵R（M×N）”说明矩阵分解方式的原理以及python实现。</p>
<h1 id="一、矩阵分解"><a href="#一、矩阵分解" class="headerlink" title="一、矩阵分解"></a>一、矩阵分解</h1><h2 id="1-案例引入"><a href="#1-案例引入" class="headerlink" title="1.案例引入"></a>1.案例引入</h2><p>有如下R(5,4)的打分矩阵：（“-”表示用户没有打分）</p>
<p>其中打分矩阵R(n,m)是n行和m列，n表示user个数，m行表示item个数<br><img src="https://img-blog.csdnimg.cn/20190727200249638.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt><br>那么，如何根据目前的矩阵R（5,4）如何对未打分的商品进行评分的预测（如何得到分值为0的用户的打分值）？</p>
<p>——矩阵分解的思想可以解决这个问题，其实这种思想可以看作是有监督的机器学习问题（回归问题）。</p>
<p>矩阵分解的过程中，,矩阵R可以近似表示为矩阵P与矩阵Q的乘积：<br><img src="https://img-blog.csdnimg.cn/2019072720060093.png" alt><br>矩阵P(n,k)表示n个user和k个特征之间的关系矩阵，这k个特征是一个中间变量，矩阵Q(k,m)的转置是矩阵Q(m,k)，矩阵Q(m,k)表示m个item和K个特征之间的关系矩阵，这里的k值是自己控制的，可以使用交叉验证的方法获得最佳的k值。为了得到近似的R(n,m)，必须求出矩阵P和Q，如何求它们呢？</p>
<h2 id="2-推导步骤"><a href="#2-推导步骤" class="headerlink" title="2.推导步骤"></a>2.推导步骤</h2><ol>
<li>首先令：<br><img src="https://img-blog.csdnimg.cn/2019072720192687.png" alt="式子1"></li>
<li>对于式子1的左边项，表示的是r^ 第i行，第j列的元素值，对于如何衡量，我们分解的好坏呢，式子2，给出了衡量标准，也就是损失函数，平方项损失，最后的目标，就是每一个元素(非缺失值)的e(i,j)的总和最小值<br> <img src="https://img-blog.csdnimg.cn/20190727202015695.png" alt="式子2"></li>
<li>使用梯度下降法获得修正的p和q分量：<ul>
<li><strong>求解损失函数的负梯度</strong>：<br><img src="https://img-blog.csdnimg.cn/20190727202620356.png" alt></li>
<li><strong>根据负梯度的方向更新变量</strong>：<br><img src="https://img-blog.csdnimg.cn/20190727202652714.png" alt></li>
</ul>
</li>
<li><p>不停迭代直到算法最终收敛（直到sum(e^2) &lt;=阈值，即梯度下降结束条件：f(x)的真实值和预测值小于自己设定的阈值）</p>
</li>
<li><p>为了防止过拟合，增加正则化项</p>
</li>
</ol>
<h2 id="3-加入正则项的损失函数求解"><a href="#3-加入正则项的损失函数求解" class="headerlink" title="3.加入正则项的损失函数求解"></a>3.加入正则项的损失函数求解</h2><ol>
<li>通常在求解的过程中，为了能够有较好的泛化能力，会在损失函数中加入正则项，以对参数进行约束，加入正则L2范数的损失函数为：<br> <img src="https://img-blog.csdnimg.cn/20190727203202194.png" alt><br> 对正则化不清楚的，公式可化为：<br> <img src="https://img-blog.csdnimg.cn/20190727203315849.png" alt></li>
<li>使用梯度下降法获得修正的p和q分量：<ul>
<li><strong>求解损失函数的负梯度</strong>：<br><img src="https://img-blog.csdnimg.cn/20190727203526974.png" alt></li>
<li><strong>根据负梯度的方向更新变量</strong>：<br><img src="https://img-blog.csdnimg.cn/20190727203554346.png" alt></li>
</ul>
</li>
</ol>
<h2 id="4-预测"><a href="#4-预测" class="headerlink" title="4.预测"></a>4.预测</h2><p>预测利用上述的过程，我们可以得到矩阵和，这样便可以为用户 i 对商品 j 进行打分：<br> <img src="https://img-blog.csdnimg.cn/20190727203756990.png" alt></p>
<h1 id="二、python代码实现"><a href="#二、python代码实现" class="headerlink" title="二、python代码实现"></a>二、python代码实现</h1><p>以下是根据上文的评分例子做的一个矩阵分解算法，并且附有代码详解。<br><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">def matrix_factorization(R,P,Q,K,steps=<span class="number">5000</span>,alpha=<span class="number">0</span>.<span class="number">0002</span>,beta=<span class="number">0</span>.<span class="number">02</span>): <span class="comment">#矩阵因子分解函数，steps：梯度下降次数；alpha：步长；beta：β。</span></span><br><span class="line">    Q=Q.T                 <span class="comment"># .T操作表示矩阵的转置</span></span><br><span class="line">    <span class="literal">result</span>=[]</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(steps): <span class="comment">#梯度下降</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len(R)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(len(R[i])):</span><br><span class="line">                    eij=R[i][j]-numpy.dot(P[i,:],Q[:,j])       <span class="comment"># .DOT表示矩阵相乘</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">                      <span class="keyword">if</span> R[i][j]&gt;<span class="number">0</span>:        <span class="comment">#限制评分大于零</span></span><br><span class="line">                        P[i][k]=P[i][k]+alpha*(<span class="number">2</span>*eij*Q[k][j]-beta*P[i][k])   <span class="comment">#增加正则化，并对损失函数求导，然后更新变量P</span></span><br><span class="line">                        Q[k][j]=Q[k][j]+alpha*(<span class="number">2</span>*eij*P[i][k]-beta*Q[k][j])   <span class="comment">#增加正则化，并对损失函数求导，然后更新变量Q</span></span><br><span class="line">        eR=numpy.dot(P,Q)  </span><br><span class="line">        e=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len(R)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(len(R[i])):</span><br><span class="line">              <span class="keyword">if</span> R[i][j]&gt;<span class="number">0</span>:</span><br><span class="line">                    e=e+pow(R[i][j]-numpy.dot(P[i,:],Q[:,j]),<span class="number">2</span>)      <span class="comment">#损失函数求和</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">                        e=e+(beta/<span class="number">2</span>)*(pow(P[i][k],<span class="number">2</span>)+pow(Q[k][j],<span class="number">2</span>)) <span class="comment">#加入正则化后的损失函数求和</span></span><br><span class="line">        <span class="literal">result</span>.append(e)</span><br><span class="line">        <span class="keyword">if</span> e&lt;<span class="number">0</span>.<span class="number">001</span>:           <span class="comment">#判断是否收敛，0.001为阈值</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> P,Q.T,<span class="literal">result</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == '__main__':   <span class="comment">#主函数</span></span><br><span class="line">    R=[                 <span class="comment">#原始矩阵</span></span><br><span class="line">        [<span class="number">5</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">        [<span class="number">4</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">5</span>],</span><br><span class="line">        [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">4</span>]</span><br><span class="line">    ]</span><br><span class="line">    R=numpy.<span class="built_in">array</span>(R)</span><br><span class="line">    N=len(R)    <span class="comment">#原矩阵R的行数</span></span><br><span class="line">    M=len(R[<span class="number">0</span>]) <span class="comment">#原矩阵R的列数</span></span><br><span class="line">    K=<span class="number">3</span>    <span class="comment">#K值可根据需求改变</span></span><br><span class="line">    P=numpy.random.rand(N,K) <span class="comment">#随机生成一个 N行 K列的矩阵</span></span><br><span class="line">    Q=numpy.random.rand(M,K) <span class="comment">#随机生成一个 M行 K列的矩阵</span></span><br><span class="line">    nP,nQ,<span class="literal">result</span>=matrix_factorization(R,P,Q,K)</span><br><span class="line">    print(R)         <span class="comment">#输出原矩阵</span></span><br><span class="line">    <span class="type">R_MF</span>=numpy.dot(nP,nQ.T)</span><br><span class="line">    print(<span class="type">R_MF</span>)      <span class="comment">#输出新矩阵</span></span><br><span class="line">    <span class="comment">#画图</span></span><br><span class="line">    plt.plot(<span class="built_in">range</span>(len(<span class="literal">result</span>)),<span class="literal">result</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"time"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"loss"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2019-07-23</span><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/推荐系统/" title="推荐系统">推荐系统 </a><a class="tag" href="/tags/矩阵分解/" title="矩阵分解">矩阵分解 </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://hpu-yz.github.io/2019/07/23/tui-jian-xi-tong-zhi-ju-zhen-fen-jie-mf-ji-qi-python-shi-xian/,Best-yz,推荐系统之矩阵分解(MF)及其python实现,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2019/07/24/duo-chong-xiang-si-du-ji-suan-de-python-shi-xian/" title="多种相似度计算方法">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2019/07/22/shu-qi-pei-xun-di-yi-ci-ce-shi-ti-zong-jie/" title="暑期培训第一次测试题总结">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'ScFNhrKDxbwGDnwPjE6xGCTm-gzGzoHsz',
  app_key:'Lwnq5xfD0M2LosaGSeDSFeqi',
  placeholder:'念念不忘，必有回响...',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'mp'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>