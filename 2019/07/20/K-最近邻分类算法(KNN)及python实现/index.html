
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>KNN算法及python实现 - Flaneur</title>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate">
    <meta name="keywords" content="Flaneur,"> 
    <meta name="description" content="走最远的路，爬最高的山，看最美的风景。,&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;KNN算法即K-Nearest Neighbor，也是机器学习十大经典算法之一。前文讲解了K-mean,"> 
    <meta name="author" content="Flaneur"> 
    <link rel="alternative" href="atom.xml" title="Flaneur" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    
    
    <link rel="stylesheet" href="/css/diaspora.css">
	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads" src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
</head>
</html>
<body class="loading">
    <span id="config-title" style="display:none">Flaneur</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="https://hpu-yz.github.io"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">KNN算法及python实现</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class="main">
        <h1 class="title">KNN算法及python实现</h1>
        <div class="stuff">
            <span>七月 20, 2019</span>
            
  <ul class="post-tags-list"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/KNN/">KNN</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/python/">python</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/机器学习/">机器学习</a></li></ul>


        </div>
        <div class="content markdown">
            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;KNN算法即K-Nearest Neighbor，也是机器学习十大经典算法之一。前文讲解了K-means算法，今天我们就继续讲KNN算法，两者看起来挺相似的，但区别还是很大的，看完本片文章你就会明白了。</p>
<h1 id="一、引入"><a href="#一、引入" class="headerlink" title="一、引入"></a>一、引入</h1><p>问题：确定绿色圆是属于红色三角形、还是蓝色正方形？<br><img src="https://img-blog.csdnimg.cn/20190729110829508.png" alt><br>KNN的思想：<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图中我们可以看到，图中的数据集是良好的数据，即都打好了label，一类是蓝色的正方形，一类是红色的三角形，那个绿色的圆形是我们待分类的数据。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果K=3，那么离绿色点最近的有2个红色三角形和1个蓝色的正方形，这3个点投票，于是绿色的这个待分类点属于红色的三角形<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果K=5，那么离绿色点最近的有2个红色三角形和3个蓝色的正方形，这5个点投票，于是绿色的这个待分类点属于蓝色的正方形<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;即如果一个样本在特征空间中的k个最相邻的样本中，大多数属于某一个类别，则该样本也属于这个类别。我们可以看到，KNN本质是基于一种数据统计的方法！其实很多机器学习算法也是基于数据统计的。</p>
<h1 id="二、KNN算法"><a href="#二、KNN算法" class="headerlink" title="二、KNN算法"></a>二、KNN算法</h1><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;KNN即K-最近邻分类算法（K-Nearest Neighbor），是一种memory-based learning，也叫instance-based learning，属于lazy learning。即它没有明显的前期训练过程，而是程序开始运行时，把数据集加载到内存后，不需要进行训练，就可以开始分类了。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;KNN也是一种监督学习算法，通过计算新数据与训练数据特征值之间的距离，然后选取K(K&gt;=1)个距离最近的邻居进行分类判(投票法)或者回归。若K=1，新数据被简单分配给其近邻的类。</p>
<h2 id="2-步骤"><a href="#2-步骤" class="headerlink" title="2.步骤"></a>2.步骤</h2><p>1）计算测试数据与各个训练数据之间的距离；</p>
<blockquote>
<p>(计算距离的方式前文讲k-means时说过，不清楚的可以去查看以下➡<a href="https://hpu-yz.github.io/2019/07/19/K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/">传送门</a>)</p>
</blockquote>
<p>2）按照距离的递增关系进行排序；</p>
<p>3）选取距离最小的K个点；</p>
<blockquote>
<p>K值是由自己来确定的</p>
</blockquote>
<p>4）确定前K个点所在类别的出现频率；</p>
<p>5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。</p>
<blockquote>
<p>说明：对于步骤5的预测分类有以下两种方法</p>
<ol>
<li>多数表决法：多数表决法类似于投票的过程，也就是在 K 个邻居中选择类别最多的种类作为测试样本的类别。</li>
<li>加权表决法：根据距离的远近，对近邻的投票进行加权，距离越近则权重越大，通过权重计算结果最大值的类为测试样本的类别。</li>
</ol>
</blockquote>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>1)  非参数统计方法：不需要引入参数<br>2)  K的选择：<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K = 1时，将待分类样本划入与其最接近的样本的类。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;K = |X|时，仅根据训练样本进行频率统计，将待分类样本划入最多的类。<br>K需要合理选择，太小容易受干扰，太大增加计算复杂性。<br>3)  算法的复杂度：维度灾难，当维数增加时，所需的训练样本数急剧增加，一般采用降维处理。</p>
<h1 id="三、算法优缺点"><a href="#三、算法优缺点" class="headerlink" title="三、算法优缺点"></a>三、算法优缺点</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ol>
<li>简单、有效。 </li>
<li>重新训练的代价较低(类别体系的变化和训练集的变化，在Web环境和电子商务应用中是很常见的)。 </li>
<li>计算时间和空间线性于训练集的规模(在一些场合不算太大)。 </li>
<li>由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。 </li>
<li>该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量较小的类域采用这种算法比较容易产生误分。 </li>
</ol>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ol>
<li>KNN算法是懒散学习方法(lazy learning)，而一些积极学习的算法要快很多。 </li>
<li>需要存储全部的训练样本 </li>
<li>输出的可解释性不强，例如决策树的可解释性较强。 </li>
<li>该算法在分类时有个主要的不足是，当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。该算法只计算最近的邻居样本，某一类的样本数量很大，那么或者这类样本并不接近目标样本，或者这类样本很靠近目标样本。无论怎样，数量并不能影响运行结果。可以采用权值的方法(和该样本距离小的邻居权值大)来改进。 </li>
<li>计算量较大。目前常用的解决方法是事先对已知样本点进行剪辑，事先去除对分类作用不大的样本。</li>
</ol>
<h1 id="四、KNN与K-means的区别"><a href="#四、KNN与K-means的区别" class="headerlink" title="四、KNN与K-means的区别"></a>四、KNN与K-means的区别</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;废话不多说，咱直接上图：<br><img src="https://img-blog.csdnimg.cn/2019072911370194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt><br>相似点：<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然两者有很大且别，但两者也有共同之处。都包含了一个过程：给定一个点，在数据集找离它最近的点，即都用到了NN(Nearest Neighbor)算法。</p>
<h1 id="五、python实例实现"><a href="#五、python实例实现" class="headerlink" title="五、python实例实现"></a>五、python实例实现</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面引入一个实例，通过python代码具体看下KNN算法的流程。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">from numpy <span class="built_in">import</span> *</span><br><span class="line"><span class="built_in">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="attr">dataSet</span> = array([[<span class="number">1.0</span>,<span class="number">1.1</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0.1</span>]])</span><br><span class="line"><span class="attr">labels</span> = ['A','A','B','B']</span><br><span class="line"></span><br><span class="line">def classify0(inX,dataSet,labels,k):</span><br><span class="line"></span><br><span class="line">    <span class="comment">#求出样本集的行数，也就是labels标签的数目</span></span><br><span class="line">    <span class="attr">dataSetSize</span> = dataSet.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#构造输入值和样本集的差值矩阵</span></span><br><span class="line">    <span class="attr">diffMat</span> = tile(inX,(dataSetSize,<span class="number">1</span>)) - dataSet</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算欧式距离</span></span><br><span class="line">    <span class="attr">sqDiffMat</span> = diffMat**<span class="number">2</span></span><br><span class="line">    <span class="attr">sqDistances</span> = sqDiffMat.sum(<span class="attr">axis=1)</span></span><br><span class="line">    <span class="attr">distances</span> = sqDistances**<span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#求距离从小到大排序的序号</span></span><br><span class="line">    <span class="attr">sortedDistIndicies</span> = distances.argsort()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#对距离最小的k个点统计对应的样本标签</span></span><br><span class="line">    <span class="attr">classCount</span> = &#123;&#125;</span><br><span class="line">    for i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment">#取第i+1邻近的样本对应的类别标签</span></span><br><span class="line">        <span class="attr">voteIlabel</span> = labels[sortedDistIndicies[i]]</span><br><span class="line">        <span class="comment">#以标签为key，标签出现的次数为value将统计到的标签及出现次数写进字典</span></span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#对字典按value从大到小排序</span></span><br><span class="line">    <span class="attr">sortedClassCount</span> = sorted(classCount.items(),<span class="attr">key=operator.itemgetter(1),reverse=True)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#返回排序后字典中最大value对应的key</span></span><br><span class="line">    return sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="attr">__name__</span> == '__main__':</span><br><span class="line">    print(classify0([<span class="number">1.1</span>,<span class="number">0</span>],dataSet,labels,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src>
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title="0" data-url="http://link.hhtjim.com/163/425570952.mp3"></li>
                        
                    
                        
                            <li title="1" data-url="http://link.hhtjim.com/163/425570952.mp3"></li>
                        
                    
                </ul>
            
        </div>
        
    <div id="gitalk-container" class="comment link" data-enable="true" data-ae="true" data-ci data-cs data-r data-o data-a data-d="false">查看评论</div>


    </div>
    
        <div class="side">
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、引入"><span class="toc-number">1.</span> <span class="toc-text">一、引入</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、KNN算法"><span class="toc-number">2.</span> <span class="toc-text">二、KNN算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-介绍"><span class="toc-number">2.1.</span> <span class="toc-text">1.介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-步骤"><span class="toc-number">2.2.</span> <span class="toc-text">2.步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特点"><span class="toc-number">2.3.</span> <span class="toc-text">特点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、算法优缺点"><span class="toc-number">3.</span> <span class="toc-text">三、算法优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#优点"><span class="toc-number">3.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#缺点"><span class="toc-number">3.2.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四、KNN与K-means的区别"><span class="toc-number">4.</span> <span class="toc-text">四、KNN与K-means的区别</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#五、python实例实现"><span class="toc-number">5.</span> <span class="toc-text">五、python实例实现</span></a></li></ol>	
        </div>
    
</div>


    </div>
</div>
</body>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>
<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>






</html>
