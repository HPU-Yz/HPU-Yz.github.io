<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Best-yz"><title>基于协同过滤（CF）算法的推荐系统 · Best-yz</title><meta name="description" content="&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 随着计算机领域技术的高速发展，电子商务时代的普及，个性化的推荐系统深入生活应用的各个方面。个性化推荐算法是推荐系统中最核心的技术，在很大程度上决定了电子商务推荐系统性能的优劣。而协同过滤推荐是个性化推荐"><meta name="keywords" content="Flaneur博客，Best-yz博客"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="https://cdn.jsdelivr.net/gh/HPU-Yz/cdn-speed/medias/logo@2x.png" style="width:127px;"><h3 title><a href="/">Best-yz</a></h3><div class="description"><p>三分热度 <br> Nothing is impossible to a willing heart.</p></div></div></div><ul class="social-links"><li><a href="https://github.com/HPU-Yz"><i class="fa fa-github"></i></a></li><li><a href="mailto:2426545812@qq.com"><i class="fa fa-envelope"></i></a></li><li><a href="http://sighttp.qq.com/authd?IDKEY=da97a3288889b7c35a1e6d914e0cb28bda9a83ec1e77cf7b"><i class="fa fa-qq"></i></a></li></ul><div class="footer"><div class="p"> <span>© 2019 - 2020 </span><i class="fa fa-star"></i><span> Best-yz</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> </span><a href="http://www.beian.miit.gov.cn/" target="_blank">&nbsp;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li><a href="/about">关于</a></li><li><a href="/guestbook">留言</a></li><li><a href="/links">友链</a></li><li><a href="/shuoshuo">说说</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>基于协同过滤（CF）算法的推荐系统</a></h3></div><div class="post-content"><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 随着计算机领域技术的高速发展，电子商务时代的普及，个性化的推荐系统深入生活应用的各个方面。个性化推荐算法是推荐系统中最核心的技术，在很大程度上决定了电子商务推荐系统性能的优劣。而协同过滤推荐是个性化推荐系统应用最为广泛的技术，协同过滤推荐主要分为基于用户的协同过滤推荐、基于项目的协同过滤推荐和基于模型的协同过滤推荐。</p>
<h1 id="一、协同过滤算法描述"><a href="#一、协同过滤算法描述" class="headerlink" title="一、协同过滤算法描述"></a>一、协同过滤算法描述</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大数据时代产生了海量的数据，里面蕴含了丰富的价值。但是，大数据体量之大、种类之繁以及产生速率之快，海量的数据并不都是有价值的，用户从海量的数据中提取有用的、针对性的信息需要花费很大的时间成本。比如，当你面对如此多的电影列表，你想找到一部最符合自己兴趣的电影，因为电影数量之多，你不可能把所有的电影简介都看一遍。那么怎么解决这个问题呢？电影平台搜集你过去看过的全部电影，分析了解你对什么类型电影感兴趣，然后针对性的把你感兴趣的电影主动的罗列给你，你不用花费太多的精力便可快速找到满足自己需求的电影。推荐算法便是为解决这类实际需求而诞生了。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 推荐系统应用数据分析技术，找出用户最可能喜欢的东西推荐给用户，现在很多电子商务网站都有这个应用。目前用的比较多、比较成熟的推荐算法是协同过滤（Collaborative Filtering，简称CF）推荐算法，CF的基本思想是根据用户之前的喜好以及其他兴趣相近的用户的选择来给用户推荐物品。<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL2hpLmNzZG4ubmV0L2F0dGFjaG1lbnQvMjAxMjAzLzE2LzBfMTMzMTkwOTY5MFhVcEkuZ2lm" alt><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图所示，在CF中，用m×n的矩阵表示用户对物品的喜好情况，一般用打分表示用户对物品的喜好程度，分数越高表示越喜欢这个物品，0表示没有买过该物品。图中行表示一个用户，列表示一个物品，Uij表示用户i对物品j的打分情况。CF分为两个过程，一个为预测过程，另一个为推荐过程。预测过程是预测用户对没有购买过的物品的可能打分值，推荐是根据预测阶段的结果推荐用户最可能喜欢的一个或Top-N个物品。</p>
<h1 id="二、协同过滤的实现"><a href="#二、协同过滤的实现" class="headerlink" title="二、协同过滤的实现"></a>二、协同过滤的实现</h1><p>要实现协同过滤的推荐算法，要进行以下三个步骤：</p>
<ul>
<li>收集数据</li>
<li>找到相似用户或物品</li>
<li>进行推荐</li>
</ul>
<h2 id="1、收集数据"><a href="#1、收集数据" class="headerlink" title="1、收集数据"></a>1、收集数据</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里的数据指的都是用户的历史行为数据，比如用户的购买历史，关注，收藏行为，或者发表了某些评论，给某个物品打了多少分等等，这些都可以用来作为数据供推荐算法使用，服务于推荐算法。需要特别指出的在于，不同的数据准确性不同，在使用时需要考虑到噪音所带来的影响。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要从用户的行为和偏好中发现规律，并基于此给予推荐，如何收集用户的偏好信息成为系统推荐效果最基础的决定因素。用户有很多方式向系统提供自己的偏好信息，而且不同的应用也可能大不相同，如下图：<br><img src="https://img-blog.csdnimg.cn/20190813212211411.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt></p>
<h2 id="2、找到相似用户或物品"><a href="#2、找到相似用户或物品" class="headerlink" title="2、找到相似用户或物品"></a>2、找到相似用户或物品</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一步其实就是计算用户间以及物品间的相似度。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于相似度的计算，现有的几种基本方法都是基于向量（Vector）的，其实也就是计算两个向量的距离，距离越近相似度越大。在推荐的场景中，在用户 - 物品偏好的二维矩阵中，我们可以将一个用户对所有物品的偏好作为一个向量来计算用户之间的相似度，或者将所有用户对某个物品的偏好作为一个向量来计算物品之间的相似度。下面我们详细介绍几种常用的相似度计算方法：<br><img src="https://img-blog.csdnimg.cn/20190813212300649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt></p>
<p>下一步是作出预测。你可以运用下面的公式做一个预测：<br><img src="https://img-blog.csdn.net/20180408164703642" alt></p>
<h2 id="3、进行推荐"><a href="#3、进行推荐" class="headerlink" title="3、进行推荐"></a>3、进行推荐</h2><h3 id="3-1、基于用户的协同过滤推荐-User-based-Collaborative-Filtering-Recommendation"><a href="#3-1、基于用户的协同过滤推荐-User-based-Collaborative-Filtering-Recommendation" class="headerlink" title="3.1、基于用户的协同过滤推荐(User-based Collaborative Filtering Recommendation)"></a>3.1、基于用户的协同过滤推荐(User-based Collaborative Filtering Recommendation)</h3><p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于用户的协同过滤推荐算法先使用统计技术寻找与目标用户有相同喜好的邻居，然后根据目标用户的邻居的喜好产生向目标用户的推荐。基本原理就是利用用户访问行为的相似性来互相推荐用户可能感兴趣的资源，如图所示：</p>
<p><img src="https://img-blog.csdn.net/20161020214409502" alt><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图示意出基于用户的协同过滤推荐机制的基本原理，假设用户 A 喜欢物品 A、物品 C，用户 B 喜欢物品 B，用户 C 喜欢物品 A 、物品 C 和物品 D；从这些用户的历史喜好信息中，我们可以发现用户 A 和用户 C 的口味和偏好是比较类似的，同时用户 C 还喜欢物品 D，那么我们可以推断用户 A 可能也喜欢物品 D，因此可以将物品 D 推荐给用户 A。<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于用户的协同过滤推荐机制和基于人口统计学的推荐机制都是计算用户的相似度，并基于“邻居”用户群计算推荐，但它们所不同的是如何计算用户的相似度，基于人口统计学的机制只考虑用户本身的特征，而基于用户的协同过滤机制可是在用户的历史偏好的数据上计算用户的相似度，它的基本假设是，喜欢类似物品的用户可能有相同或者相似的口味和偏好。</p>
<h3 id="3-2、基于项目的协同过滤推荐-Item-based-Collaborative-Filtering-Recommendation"><a href="#3-2、基于项目的协同过滤推荐-Item-based-Collaborative-Filtering-Recommendation" class="headerlink" title="3.2、基于项目的协同过滤推荐(Item-based Collaborative Filtering Recommendation)"></a>3.2、基于项目的协同过滤推荐(Item-based Collaborative Filtering Recommendation)</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据所有用户对物品或者信息的评价，发现物品和物品之间的相似度，然后根据用户的历史偏好信息将类似的物品推荐给该用户，如图所示：<br><img src="https://img-blog.csdn.net/20160821160630777" alt><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图表明基于项目的协同过滤推荐的基本原理，用户A喜欢物品A和物品C，用户B喜欢物品A、物品B和物品C，用户C喜欢物品A，从这些用户的历史喜好中可以认为物品A与物品C比较类似，喜欢物品A的都喜欢物品C，基于这个判断用户C可能也喜欢物品C，所以推荐系统将物品C推荐给用户C。<br>       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 基于项目的协同过滤推荐和基于内容的协同过滤推荐都是基于物品相似度预测推荐，只是相似度度量的方法不一样，前者是从用户历史的偏好推断，而后者是基于物品本身的属性特征信息。</p>
<h3 id="3-3、UserCF和ItemCF的区别"><a href="#3-3、UserCF和ItemCF的区别" class="headerlink" title="3.3、UserCF和ItemCF的区别"></a>3.3、UserCF和ItemCF的区别</h3><p><img src="https://img-blog.csdn.net/20170107105218959" alt></p>
<h1 id="三、算法实例"><a href="#三、算法实例" class="headerlink" title="三、算法实例"></a>三、算法实例</h1><p>以ItemCF为例子具体介绍下整个算法流程。<br><strong>算法流程：</strong></p>
<ol>
<li>构建用户–&gt;物品的倒排；</li>
<li>构建物品与物品的同现矩阵；</li>
<li>计算物品之间的相似度，即计算相似矩阵；</li>
<li>根据用户的历史记录，给用户推荐物品；</li>
</ol>
<h2 id="算法流程1"><a href="#算法流程1" class="headerlink" title="算法流程1"></a>算法流程1</h2><p>构建用户–&gt;物品的倒排<br>如下表，行表示用户，列表示物品，1表示用户喜欢该物品<br><img src="https://img-blog.csdnimg.cn/20190814085502109.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt></p>
<figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">例如<span class="keyword">python</span>构建的数据格式如下</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">'A'</span>: &#123;<span class="string">'a'</span>: <span class="string">'1'</span>, <span class="string">'b'</span>: <span class="string">'1'</span>, <span class="string">'d'</span>: <span class="string">'1'</span>&#125;, </span><br><span class="line"><span class="string">'B'</span>: &#123;<span class="string">'c'</span>: <span class="string">'1'</span>, <span class="string">'b'</span>: <span class="string">'1'</span>, <span class="string">'e'</span>: <span class="string">'1'</span>&#125;, </span><br><span class="line"><span class="string">'C'</span>: &#123;<span class="string">'c'</span>: <span class="string">'1'</span>, <span class="string">'d'</span>: <span class="string">'1'</span>&#125;, </span><br><span class="line"><span class="string">'D'</span>: &#123;<span class="string">'c'</span>: <span class="string">'1'</span>, <span class="string">'b'</span>: <span class="string">'1'</span>, <span class="string">'d'</span>: <span class="string">'1'</span>&#125;,</span><br><span class="line"><span class="string">'E'</span>: &#123;<span class="string">'a'</span>: <span class="string">'1'</span>, <span class="string">'d'</span>: <span class="string">'1'</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="算法流程2"><a href="#算法流程2" class="headerlink" title="算法流程2"></a>算法流程2</h2><p>构建物品与物品的同现矩阵</p>
<p>共现矩阵C表示同时喜欢两个物品的用户数，是根据用户物品倒排表计算出来的。如根据上面的用户物品倒排表可以计算出如下的共现矩阵C：<br><img src="https://img-blog.csdnimg.cn/20190814085654185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt></p>
<h2 id="算法流程3"><a href="#算法流程3" class="headerlink" title="算法流程3"></a>算法流程3</h2><p>计算物品之间的相似度，即计算相似矩阵</p>
<p>其中两个物品之间的相似度如何计算？<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;设|N(i)|表示喜欢物品i的用户数，|N(i)⋂N(j)|表示同时喜欢物品i，j的用户数，则物品i与物品j的相似度为： </p>
<p><img src="https://img-blog.csdnimg.cn/20190814090106195.png" alt></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)式有一个问题，当物品j是一个很热门的商品时，人人都喜欢，那么wijwij就会很接近于1，即(1)式会让很多物品都和热门商品有一个很大的相似度，所以可以改进一下公式：</p>
<p><img src="https://img-blog.csdnimg.cn/2019081409030146.png" alt></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;算法流程2中的共现矩阵C其实就是式(2)的分子，矩阵N（用于计算分母）表示喜欢某物品的用户数（是总的用户数），则(2)式中的分母便很容易求解出来了。</p>
<p>矩阵N如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20190814090318574.png" alt></p>
<p>利用式（2）便能计算物品之间的余弦相似矩阵如下：</p>
<p><img src="https://img-blog.csdnimg.cn/2019081409034757.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt></p>
<h2 id="算法流程4"><a href="#算法流程4" class="headerlink" title="算法流程4"></a>算法流程4</h2><p>根据用户的历史记录，给用户推荐物品；</p>
<p>最终推荐的是什么物品，是由预测兴趣度决定的。</p>
<p><strong>物品j预测兴趣度=用户喜欢的物品i的兴趣度×物品i和物品j的相似度</strong></p>
<p>例如：A用户喜欢a，b，d ，兴趣度分别为1,1,1</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;推荐c的预测兴趣度=1X0.67+1X0.58=1.25<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;推荐e的预测兴趣度=1X0.58=0.58</p>
<h1 id="四、python实现案例"><a href="#四、python实现案例" class="headerlink" title="四、python实现案例"></a>四、python实现案例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="comment">#1.构建用户--&gt;物品的倒排</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">(files)</span>:</span></span><br><span class="line">    data =&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> files:</span><br><span class="line">        user,score,item=line.split(<span class="string">","</span>)  <span class="comment">#按","将每组数据单独分开,并将每组的数据赋予对应变量</span></span><br><span class="line">        data.setdefault(user,&#123;&#125;)</span><br><span class="line">        data[user][item]=score</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"----1.用户：物品的倒排----"</span>)</span><br><span class="line">    <span class="keyword">print</span> (data)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.计算</span></span><br><span class="line"><span class="comment"># 2.1 构造物品--&gt;物品的共现矩阵</span></span><br><span class="line"><span class="comment"># 2.2 计算物品与物品的相似矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">similarity</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="comment"># 2.1 构造物品：物品的共现矩阵</span></span><br><span class="line">    N=&#123;&#125;;<span class="comment">#喜欢物品i的总人数</span></span><br><span class="line">    C=&#123;&#125;;<span class="comment">#喜欢物品i也喜欢物品j的人数</span></span><br><span class="line">    <span class="keyword">for</span> user,item <span class="keyword">in</span> data.items():</span><br><span class="line">        <span class="keyword">for</span> i,score <span class="keyword">in</span> item.items():</span><br><span class="line">            N.setdefault(i,<span class="number">0</span>)</span><br><span class="line">            N[i]+=<span class="number">1</span></span><br><span class="line">            C.setdefault(i,&#123;&#125;)</span><br><span class="line">            <span class="keyword">for</span> j,scores <span class="keyword">in</span> item.items():</span><br><span class="line">                <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> i:</span><br><span class="line">                    C[i].setdefault(j,<span class="number">0</span>)</span><br><span class="line">                    C[i][j]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"---2.构造的共现矩阵---"</span>)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'N:'</span>,N)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'C:'</span>,C)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#2.2 计算物品与物品的相似矩阵</span></span><br><span class="line">    W=&#123;&#125;;</span><br><span class="line">    <span class="keyword">for</span> i,item <span class="keyword">in</span> C.items():</span><br><span class="line">        W.setdefault(i,&#123;&#125;)</span><br><span class="line">        <span class="keyword">for</span> j,item2 <span class="keyword">in</span> item.items():</span><br><span class="line">            W[i].setdefault(j,<span class="number">0</span>)</span><br><span class="line">            W[i][j]=C[i][j]/sqrt(N[i]*N[j])</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"---3.构造的相似矩阵---"</span>)</span><br><span class="line">    <span class="keyword">print</span> (W)</span><br><span class="line">    <span class="keyword">return</span> W</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.根据用户的历史记录，给用户推荐物品</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recommandList</span><span class="params">(data,W,user,k=<span class="number">3</span>,N=<span class="number">10</span>)</span>:</span></span><br><span class="line">    rank=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i,score <span class="keyword">in</span> data[user].items():<span class="comment">#获得用户user历史记录，如A用户的历史记录为&#123;'a': '1', 'b': '1', 'd': '1'&#125;</span></span><br><span class="line">        <span class="keyword">for</span> j,w <span class="keyword">in</span> sorted(W[i].items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)[<span class="number">0</span>:k]:<span class="comment">#获得与物品i相似的k个物品</span></span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> data[user].keys():<span class="comment">#该相似的物品不在用户user的记录里</span></span><br><span class="line">                rank.setdefault(j,<span class="number">0</span>)</span><br><span class="line">                rank[j]+=float(score) * w</span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"---4.推荐----"</span>)</span><br><span class="line">    <span class="keyword">print</span> (sorted(rank.items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)[<span class="number">0</span>:N])</span><br><span class="line">    <span class="keyword">return</span> sorted(rank.items(),key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)[<span class="number">0</span>:N]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#用户，兴趣度，物品</span></span><br><span class="line">    uid_score_bid = [<span class="string">'A,1,a'</span>, <span class="string">'A,1,b'</span>, <span class="string">'A,1,d'</span>, <span class="string">'B,1,b'</span>, <span class="string">'B,1,c'</span>, <span class="string">'B,1,e'</span>, <span class="string">'C,1,c'</span>, <span class="string">'C,1,d'</span>, <span class="string">'D,1,b'</span>, <span class="string">'D,1,c'</span>, <span class="string">'D,1,d'</span>,</span><br><span class="line">                     <span class="string">'E,1,a'</span>, <span class="string">'E,1,d'</span>]</span><br><span class="line">    data=loadData(uid_score_bid)<span class="comment">#获得数据</span></span><br><span class="line">    W=similarity(data)<span class="comment">#计算物品相似矩阵</span></span><br><span class="line">    recommandList(data,W,<span class="string">'A'</span>,<span class="number">3</span>,<span class="number">10</span>)<span class="comment">#推荐</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了方便理解python的实现过程，这里只用了少数数据集并是手输上去的，具体情况运用可再加段代码用于读取并处理数据文件。</p>
<h1 id="五、算法的优缺点"><a href="#五、算法的优缺点" class="headerlink" title="五、算法的优缺点"></a>五、算法的优缺点</h1><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个算法实现起来也比较简单，但是在实际应用中有时候也会有问题的。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如一些非常流行的商品可能很多人都喜欢，这种商品推荐给你就没什么意义了，所以计算的时候需要对这种商品加一个权重或者把这种商品完全去掉也行。</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再有，对于一些通用的东西，比如买书的时候的工具书，如现代汉语词典，新华字典神马的，通用性太强了，推荐也没什么必要了。</p>
<p><strong>UserCF和ItemCF优缺点的对比</strong><br><img src="https://img-blog.csdnimg.cn/20190814083729968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzQxMzEy,size_16,color_FFFFFF,t_70" alt></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2019-07-28</span><i class="fa fa-tag"></i><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a><a class="tag" href="/tags/推荐系统/" title="推荐系统">推荐系统 </a><a class="tag" href="/tags/协同过滤（CF）/" title="协同过滤（CF）">协同过滤（CF） </a><span class="leancloud_visitors"></span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,https://hpu-yz.github.io/2019/07/28/ji-yu-xie-tong-guo-lu-cf-suan-fa-de-tui-jian-xi-tong/,Best-yz,基于协同过滤（CF）算法的推荐系统,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2019/07/30/juan-ji-shen-jing-wang-luo-cnn/" title="卷积神经网络（CNN）">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2019/07/26/ren-gong-shen-jing-wang-luo-ann/" title="人工神经网络（ANN）">下一篇</a></li></ul></div><script src="/js/visitors.js"></script><a id="comments"></a><div id="vcomments" style="margin:0 30px;"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//cdn.jsdelivr.net/gh/xcss/valine@latest/dist/Valine.min.js"></script><script>var valine = new Valine({
  el:'#vcomments',
  notify:false || false, 
  verify:false|| false, 
  app_id:'ScFNhrKDxbwGDnwPjE6xGCTm-gzGzoHsz',
  app_key:'Lwnq5xfD0M2LosaGSeDSFeqi',
  placeholder:'念念不忘，必有回响...',
  path: window.location.pathname,
  serverURLs: '',
  visitor:true,
  recordIP:true,
  avatar:'monsterid'
})</script></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script src="/js/baidu-tongji.js"></script></body></html>