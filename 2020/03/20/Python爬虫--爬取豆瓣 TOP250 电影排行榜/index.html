<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="Hexo,博客，python，C语言,机器学习，人工智能">
  
  
    <meta name="description" content="走最远的路，爬最高的山，看最美的风景。">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    Python爬虫--爬取豆瓣 TOP250 电影排行榜 |
    
    Flaneur</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>
</html>
<body>
<main class="content">
  <section class="outer">
  <article id="post-Python爬虫--爬取豆瓣 TOP250 电影排行榜" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python爬虫--爬取豆瓣 TOP250 电影排行榜
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2020/03/20/Python爬虫--爬取豆瓣 TOP250 电影排行榜/" class="article-date">
  <time datetime="2020-03-19T16:00:00.000Z" itemprop="datePublished">2020-03-20</time>
</a>
        
  <div class="article-category">
    <a class="article-category-link" href="/categories/python/">python</a> / <a class="article-category-link" href="/categories/python/爬虫/">爬虫</a>
  </div>

      </div>
    

    <div class="article-entry" itemprop="articleBody">
      

      

      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本篇讲介绍一个简单的Python爬虫案例–爬取豆瓣 TOP250 电影排行榜。<br><a id="more"></a><br>很多朋友在看一部电影前都喜欢先找一下网友们对该片的评价。</p>
<p>说到电影评分的网站，除了国外的 IMDB 和烂番茄，国内要数豆瓣最为出名。</p>
<p>主要原因是豆瓣有一套完整的评分和防水军机制 。</p>
<p>在这套机制下，豆瓣评分高的电影不一定是所有人都喜欢的，但是豆瓣评分低的电影，一定是实打实的烂片！</p>
<p>虽然每个人的喜好偏爱不同，但通常豆瓣评分 8 分以上的电影，都是值得一看的。</p>
<p>豆瓣还专门提供了一个 TOP250 的电影链接 -&gt; <a href="https://movie.douban.com/top250" target="_blank" rel="noopener">https://movie.douban.com/top250</a></p>
<h1 id="爬取思路"><a href="#爬取思路" class="headerlink" title="爬取思路"></a>爬取思路</h1><p>爬取的过程很好理解，这里只需要两个过程：<br>① 从服务器上下载所需页面<br>② 解析这个页面，得到自己需要有用的内容</p>
<h3 id="①抓取页面"><a href="#①抓取页面" class="headerlink" title="①抓取页面"></a>①抓取页面</h3><p>有的人可能会利用 urllib 模块实现网络抓取功能。但在 Python 中，有一个更好地替代者——Requests。Requests 简化了 urllib 的诸多冗杂且无意义的操作，并提供了更强大的功能。<br>所以在这里我们使用 Requests 模块的 get() 方法从服务器上来下载这个页面。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"https://movie.douban.com/top250"</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3314.0 Safari/537.36 SE 2.X MetaSr 1.0"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">res = requests.get(url,headers=headers)</span><br></pre></td></tr></table></figure>
<p>res就是我们需要的这个页面的资源，我们不妨打开来看看是不是</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"豆瓣电影.txt"</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(res.text)</span><br></pre></td></tr></table></figure>
<p>打开文本如下图<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zbG9tb28ub3NzLWNuLWJlaWppbmcuYWxpeXVuY3MuY29tLzJkZTI1MDMzZTQ0NGY3NTc2ZTRlNDZlYmU2Mjg1YzllLm1kLnBuZw?x-oss-process=image/format,png" alt><br>我们可以看出这确实是当前网页的资源，所以我们就抓取成功了。</p>
<h2 id="②解析页面"><a href="#②解析页面" class="headerlink" title="②解析页面"></a>②解析页面</h2><p>解析网页内容推荐使用 BeautifulSoup 模块，它可以化腐朽为神奇，将一个复杂的网页结构转化为书籍目录的形式供你浏览。<br>例如，我们现在需要解析提取出当前页面的电影名字</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line">soup = bs4.BeautifulSoup(res.text,<span class="string">"html.parser"</span>)</span><br><span class="line">targets = soup.find_all(<span class="string">"div"</span>,class_=<span class="string">"hd"</span>)</span><br><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> targets:</span><br><span class="line">    print(each.a.span.text)</span><br></pre></td></tr></table></figure>
<p>可以得到如下结果</p>
<blockquote>
<p>肖申克的救赎<br>霸王别姬<br>阿甘正传<br>这个杀手不太冷<br>美丽人生<br>泰坦尼克号<br>千与千寻<br>辛德勒的名单<br> 盗梦空间<br> 忠犬八公的故事<br> 海上钢琴师<br>机器人总动员<br>三傻大闹宝莱坞<br>楚门的世界<br>放牛班的春天<br> 星际穿越<br> 大话西游之大圣娶亲<br> 熔炉<br> 疯狂动物城<br> 无间道<br> 龙猫<br> 教父<br> 当幸福来敲门<br>怦然心动<br>触不可及</p>
</blockquote>
<p>这里你可能就会有疑问，这些数据是怎么得来的呢？<br>我们先来看下 HTML 源代码：<br><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zbG9tb28ub3NzLWNuLWJlaWppbmcuYWxpeXVuY3MuY29tL2E0MDcxYzNhNmYyZDUzMjVjMWJhYzJhMDQ4OTQ2Zjk4Lm1kLnBuZw?x-oss-process=image/format,png" alt><br>发现每个电影的标题都是位于 <code>&lt;div class=&quot;hd&quot;&gt;...&lt;/div&gt;</code> 标签中的，它的从属关系是：<code>div -&gt; a -&gt; span</code>。</p>
<p>所以我们先调用 find_all() 方法，找到所有 class=”hd” 的 div 标签，然后按照从属关系即可直接取出电影名。<br>同理，我们借用此发方法来解析提取出电影的评分、介绍等需要的信息。</p>
<h2 id="附加问题"><a href="#附加问题" class="headerlink" title="附加问题"></a>附加问题</h2><p>我们刚才解析提取的仅仅是第一页的页面，那么还有第二、第三、第四页……呢？</p>
<p>其实，解决起来也很简单，我们可以使用for循环来对每一页进行上述的两个过程。</p>
<p>但，我们此时又有新的问题，我们不可能每抓取一次，就重新输入下一网页的链接地址，这样很麻烦，效率也不高。</p>
<p> 我们可以分析每一页的链接：</p>
<blockquote>
<p> 第一页：<a href="https://movie.douban.com/top250" target="_blank" rel="noopener">https://movie.douban.com/top250</a><br>第二页：<a href="https://movie.douban.com/top250?start=25" target="_blank" rel="noopener">https://movie.douban.com/top250?start=25</a><br>第三页：<a href="https://movie.douban.com/top250?start=50" target="_blank" rel="noopener">https://movie.douban.com/top250?start=50</a><br>第四页：<a href="https://movie.douban.com/top250?start=75" target="_blank" rel="noopener">https://movie.douban.com/top250?start=75</a><br>第五页：<a href="https://movie.douban.com/top250?start=100" target="_blank" rel="noopener">https://movie.douban.com/top250?start=100</a><br> … …<br> …. …</p>
</blockquote>
<p>我们可以发现这样的规律：<br>每一次的更新的 <code>url = https://movie.douban.com/top250 + &#39;/?start=&#39; + str(25*i)</code>其中<code>i</code>可以表示为页数-1</p>
<p>咦，这个时候，你可能会有疑问，我们怎么知道一共有多少页呢，不能一直for循环无穷吧。</p>
<p>那当然不可能的了，我们可以按第二步解析网页方式来获取页数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">depth = soup.find(<span class="string">'span'</span>,class_=<span class="string">'next'</span>).previous_sibling.previous_sibling.text</span><br></pre></td></tr></table></figure>
<p>注意，这个返回的<code>depth</code>是给字符串形式，需要<code>int()</code></p>
<p>这样结合刚才的过程，就可以迭代每一页了</p>
<h1 id="代码清单"><a href="#代码清单" class="headerlink" title="代码清单"></a>代码清单</h1><p>感兴趣的话，可以试一试哦</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> bs4</span><br><span class="line"></span><br><span class="line"><span class="comment">#抓取网页</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_url</span><span class="params">(url)</span>:</span></span><br><span class="line">    headers = &#123;<span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3314.0 Safari/537.36 SE 2.X MetaSr 1.0"</span>&#125;</span><br><span class="line">    res = requests.get(url,headers=headers)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="comment">#得到总页数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_depth</span><span class="params">(res)</span>:</span></span><br><span class="line">    soup = bs4.BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</span><br><span class="line">    depth = soup.find(<span class="string">'span'</span>,class_=<span class="string">'next'</span>).previous_sibling.previous_sibling.text</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> int(depth)</span><br><span class="line"></span><br><span class="line"><span class="comment">#解析网页，提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_movies</span><span class="params">(res)</span>:</span></span><br><span class="line">    soup = bs4.BeautifulSoup(res.text,<span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line">    names = []</span><br><span class="line">    target = soup.find_all(<span class="string">'div'</span>,class_=<span class="string">'hd'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> target:</span><br><span class="line">        names.append(i.a.span.text)</span><br><span class="line"></span><br><span class="line">    ranks = []</span><br><span class="line">    target = soup.find_all(<span class="string">'span'</span>,class_=<span class="string">'rating_num'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> target:</span><br><span class="line">        ranks.append(i.text)</span><br><span class="line"></span><br><span class="line">    messages = []</span><br><span class="line">    target = soup.find_all(<span class="string">'div'</span>,class_=<span class="string">'bd'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> target:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            messages.append(i.p.text.split(<span class="string">'\n'</span>)[<span class="number">1</span>].strip() + i.p.text.split(<span class="string">'\n'</span>)[<span class="number">2</span>].strip())</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line">    length = len(names)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</span><br><span class="line">        result.append(names[i] + <span class="string">','</span> +ranks[i] + <span class="string">','</span> + messages[i] + <span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    host = <span class="string">"https://movie.douban.com/top250"</span></span><br><span class="line">    res = open_url(host)</span><br><span class="line">    depth = find_depth(res)</span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</span><br><span class="line">        url = host + <span class="string">'/?start='</span> + str(<span class="number">25</span>*i)</span><br><span class="line">        res = open_url(url)</span><br><span class="line">        result.extend(find_movies(res))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"豆瓣TOP250电影.txt"</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> result:</span><br><span class="line">            f.write(each)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="嘟嘟"><a href="#嘟嘟" class="headerlink" title="嘟嘟"></a>嘟嘟</h2><p>我的博客即将同步至腾讯云+社区，邀请大家一同入驻：<a href="https://cloud.tencent.com/developer/support-plan?invite_code=3c2lknoq16w4k" target="_blank" rel="noopener">https://cloud.tencent.com/developer/support-plan?invite_code=3c2lknoq16w4k</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hpu-yz.github.io/2020/03/20/Python爬虫--爬取豆瓣 TOP250 电影排行榜/" data-id="ck7zyirev0000psuh4emsr5ey" class="article-share-link">分享</a>
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
    
      <a href="/2020/03/18/【小王子】“正因为你为你的玫瑰花费了时间，这才使你的玫瑰变得如此重要。”/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">【小王子】“正因为你为你的玫瑰花费了时间，这才使你的玫瑰变得如此重要。”</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 Flaneur</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>

<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/favicon.ico" alt="Flaneur"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">主页</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">归档</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">相册</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">关于</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/tags">友链</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="搜索">
        <i class="fe fe-search"></i>
        搜索
      </a>
    </li>
  </ul>
</nav>

<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>

<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>
<script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/snap.svg-min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>


  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/search.js"></script>


<script src="/js/ocean.js"></script>

</body>
</html>